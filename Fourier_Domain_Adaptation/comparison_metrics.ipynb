{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ac9d98",
   "metadata": {},
   "source": [
    "# Comparison metrics\n",
    "\n",
    "Because we cannot trust the human eyes to make comparison between pictures, especially if the eye is French and colorblind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959ed37",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d892d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, os.path.join(\"..\", \"..\", \"src\"))\n",
    "\n",
    "import torch\n",
    "import pyvips\n",
    "import deeplake\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage import io, color, filters\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine\n",
    "import cv2\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b61145",
   "metadata": {},
   "source": [
    "Functions to migrate image appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2551c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_freq_mutate_np( amp_src, amp_trg, L=0.1 ):\n",
    "    a_src = np.fft.fftshift( amp_src, axes=(-2, -1) )\n",
    "    a_trg = np.fft.fftshift( amp_trg, axes=(-2, -1) )\n",
    "\n",
    "    _, h, w = a_src.shape\n",
    "    b = (  np.floor(np.amin((h,w))*L)  ).astype(int)\n",
    "    c_h = np.floor(h/2.0).astype(int)\n",
    "    c_w = np.floor(w/2.0).astype(int)\n",
    "\n",
    "    h1 = c_h-b\n",
    "    h2 = c_h+b+1\n",
    "    w1 = c_w-b\n",
    "    w2 = c_w+b+1\n",
    "\n",
    "    a_src[:,h1:h2,w1:w2] = a_trg[:,h1:h2,w1:w2]\n",
    "    a_src = np.fft.ifftshift( a_src, axes=(-2, -1) )\n",
    "    return a_src\n",
    "\n",
    "def modif_FDA_source_to_target_np( src_img, amp_trg, L=0.1 ):\n",
    "    fft_src_np = np.fft.fft2( src_img, axes=(-2, -1) )\n",
    "    amp_src, pha_src = np.abs(fft_src_np), np.angle(fft_src_np)\n",
    "    amp_src_ = low_freq_mutate_np( amp_src, amp_trg, L=L )\n",
    "    fft_src_ = amp_src_ * np.exp( 1j * pha_src )\n",
    "    src_in_trg = np.fft.ifft2( fft_src_, axes=(-2, -1) )\n",
    "    src_in_trg = np.real(src_in_trg)\n",
    "\n",
    "    return src_in_trg\n",
    "\n",
    "def image_to_label(src_img, label, L_hyperparam=0.1):\n",
    "    # computes the transformation of KBio images to the label-based amplitude\n",
    "    trg_amp = np.load(f\"/home/leolr-int/ASTAR_internship/Fourier_Domain_Adaptation/stored_amplitude/label_based_average/average_label_{label}_akoya.npy\")\n",
    "    return modif_FDA_source_to_target_np( src_img, trg_amp, L=L_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6146fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage import color, filters\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_preprocess_image(img_array):\n",
    "    \"\"\"Load image from numpy array and convert to appropriate format\"\"\"\n",
    "    img = img_array.copy()\n",
    "\n",
    "    # Convert to grayscale if needed for some metrics\n",
    "    if len(img.shape) == 3:\n",
    "        img_gray = color.rgb2gray(img)\n",
    "    else:\n",
    "        img_gray = img\n",
    "\n",
    "    # Normalize to [0, 1] range\n",
    "    if img.max() > 1:\n",
    "        img = img.astype(np.float64) / 255.0\n",
    "        img_gray = img_gray.astype(np.float64)\n",
    "\n",
    "    return img, img_gray\n",
    "\n",
    "def compute_similarity_metrics(original, comparison, original_gray, comparison_gray):\n",
    "    \"\"\"Compute various similarity metrics between two images\"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # 1. Structural Similarity Index (SSIM)\n",
    "    metrics['SSIM'] = ssim(original_gray, comparison_gray, data_range=1.0)\n",
    "\n",
    "    # 2. Peak Signal-to-Noise Ratio (PSNR)\n",
    "    metrics['PSNR'] = psnr(original, comparison, data_range=1.0)\n",
    "\n",
    "    # 3. Mean Squared Error (MSE)\n",
    "    metrics['MSE'] = mse(original, comparison)\n",
    "\n",
    "    # 4. Root Mean Squared Error (RMSE)\n",
    "    metrics['RMSE'] = np.sqrt(metrics['MSE'])\n",
    "\n",
    "    # 5. Mean Absolute Error (MAE)\n",
    "    metrics['MAE'] = np.mean(np.abs(original - comparison))\n",
    "\n",
    "    # 6. Normalized Cross-Correlation (NCC)\n",
    "    original_flat = original_gray.flatten()\n",
    "    comparison_flat = comparison_gray.flatten()\n",
    "    correlation, _ = pearsonr(original_flat, comparison_flat)\n",
    "    metrics['Correlation'] = correlation\n",
    "\n",
    "    # 7. Cosine Similarity\n",
    "    metrics['Cosine_Similarity'] = 1 - cosine(original_flat, comparison_flat)\n",
    "\n",
    "    # 8. Histogram Intersection (for color images)\n",
    "    if len(original.shape) == 3:\n",
    "        original_uint8 = (original * 255).astype(np.uint8)\n",
    "        comparison_uint8 = (comparison * 255).astype(np.uint8)\n",
    "        hist_orig = cv2.calcHist([original_uint8], [0, 1, 2], None, [50, 50, 50], [0, 256, 0, 256, 0, 256])\n",
    "        hist_comp = cv2.calcHist([comparison_uint8], [0, 1, 2], None, [50, 50, 50], [0, 256, 0, 256, 0, 256])\n",
    "        metrics['Histogram_Intersection'] = cv2.compareHist(hist_orig, hist_comp, cv2.HISTCMP_INTERSECT)\n",
    "\n",
    "    # 9. Edge-based similarity using Sobel filters\n",
    "    edges_orig = filters.sobel(original_gray)\n",
    "    edges_comp = filters.sobel(comparison_gray)\n",
    "    edge_similarity = ssim(edges_orig, edges_comp, data_range=edges_orig.max() - edges_orig.min())\n",
    "    metrics['Edge_SSIM'] = edge_similarity\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def create_difference_visualizations(original, comparison, original_gray, comparison_gray, title):\n",
    "    \"\"\"Create various difference visualizations\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle(f'Difference Analysis: {title}', fontsize=16)\n",
    "\n",
    "    # Original image\n",
    "    axes[0, 0].imshow(original, cmap='gray' if len(original.shape) == 2 else None)\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "\n",
    "    # Comparison image\n",
    "    axes[0, 1].imshow(comparison, cmap='gray' if len(comparison.shape) == 2 else None)\n",
    "    axes[0, 1].set_title('Comparison Image')\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    # Absolute difference\n",
    "    abs_diff = np.abs(original_gray - comparison_gray)\n",
    "    im1 = axes[0, 2].imshow(abs_diff, cmap='hot')\n",
    "    axes[0, 2].set_title('Absolute Difference')\n",
    "    axes[0, 2].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[0, 2])\n",
    "\n",
    "    # Squared difference\n",
    "    sq_diff = (original_gray - comparison_gray) ** 2\n",
    "    im2 = axes[1, 0].imshow(sq_diff, cmap='hot')\n",
    "    axes[1, 0].set_title('Squared Difference')\n",
    "    axes[1, 0].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[1, 0])\n",
    "\n",
    "    # Difference histogram\n",
    "    diff_flat = (original_gray - comparison_gray).flatten()\n",
    "    axes[1, 1].hist(diff_flat, bins=50, alpha=0.7, color='blue')\n",
    "    axes[1, 1].set_title('Difference Histogram')\n",
    "    axes[1, 1].set_xlabel('Pixel Difference')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # SSIM map\n",
    "    ssim_map = ssim(original_gray, comparison_gray, data_range=1.0, full=True)[1]\n",
    "    im3 = axes[1, 2].imshow(ssim_map, cmap='RdYlBu')\n",
    "    axes[1, 2].set_title('SSIM Map')\n",
    "    axes[1, 2].axis('off')\n",
    "    plt.colorbar(im3, ax=axes[1, 2])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_images(original, comparison_paths, save_results=True):\n",
    "    \"\"\"Main function to analyze image similarities\"\"\"\n",
    "\n",
    "    # Load original image\n",
    "    original, original_gray = load_and_preprocess_image(original)\n",
    "    print(f\"Original image shape: {original.shape}\")\n",
    "\n",
    "    # Store all results\n",
    "    all_metrics = {}\n",
    "\n",
    "    # Compare each image with the original\n",
    "    for i, comp_path in enumerate(comparison_paths):\n",
    "        print(f\"\\nProcessing comparison image {i+1}\")\n",
    "\n",
    "        # Load comparison image\n",
    "        comparison, comparison_gray = load_and_preprocess_image(comp_path)\n",
    "\n",
    "        # Check if images have the same dimensions\n",
    "        if original.shape != comparison.shape:\n",
    "            print(f\"Warning: Shape mismatch. Original: {original.shape}, Comparison: {comparison.shape}\")\n",
    "            # Resize comparison to match original\n",
    "            if len(comparison.shape) == 3:\n",
    "                comparison = cv2.resize(comparison, (original.shape[1], original.shape[0]))\n",
    "            comparison_gray = cv2.resize(comparison_gray, (original.shape[1], original.shape[0]))\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = compute_similarity_metrics(original, comparison, original_gray, comparison_gray)\n",
    "        all_metrics[f'Image_{i+1}'] = metrics\n",
    "\n",
    "        # Create visualizations\n",
    "        fig = create_difference_visualizations(original, comparison, original_gray, comparison_gray, f'Image {i+1}')\n",
    "\n",
    "        if save_results:\n",
    "            fig.savefig(f'comparison_image_{i+1}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Create summary comparison\n",
    "    create_summary_comparison(all_metrics, save_results)\n",
    "\n",
    "    return all_metrics\n",
    "\n",
    "def create_summary_comparison(all_metrics, save_results=True):\n",
    "    \"\"\"Create summary comparison of all metrics\"\"\"\n",
    "\n",
    "    # Convert to DataFrame for easier plotting\n",
    "    df = pd.DataFrame(all_metrics).T\n",
    "\n",
    "    # Create summary plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Summary Comparison of All Images', fontsize=16)\n",
    "\n",
    "    # SSIM comparison\n",
    "    ssim_values = df['SSIM'].values\n",
    "    axes[0, 0].bar(df.index, ssim_values, color='skyblue', alpha=0.7)\n",
    "    axes[0, 0].set_title('Structural Similarity Index (SSIM)')\n",
    "    axes[0, 0].set_ylabel('SSIM Value')\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    for i, v in enumerate(ssim_values):\n",
    "        axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "    # PSNR comparison\n",
    "    psnr_values = df['PSNR'].values\n",
    "    axes[0, 1].bar(df.index, psnr_values, color='lightgreen', alpha=0.7)\n",
    "    axes[0, 1].set_title('Peak Signal-to-Noise Ratio (PSNR)')\n",
    "    axes[0, 1].set_ylabel('PSNR (dB)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    for i, v in enumerate(psnr_values):\n",
    "        axes[0, 1].text(i, v + 0.5, f'{v:.1f}', ha='center', va='bottom')\n",
    "\n",
    "    # Multiple metrics heatmap\n",
    "    metrics_subset = ['SSIM', 'Correlation', 'Cosine_Similarity', 'PSNR', 'MSE', 'MAE']\n",
    "    df_subset = df[metrics_subset]\n",
    "\n",
    "    # Normalize metrics for better visualization (0-1 scale)\n",
    "    df_normalized = df_subset.copy()\n",
    "    df_normalized['PSNR'] = df_normalized['PSNR'] / df_normalized['PSNR'].max()\n",
    "    df_normalized['MSE'] = 1 - (df_normalized['MSE'] / df_normalized['MSE'].max())  # Invert MSE\n",
    "    df_normalized['MAE'] = 1 - (df_normalized['MAE'] / df_normalized['MAE'].max())  # Invert MAE\n",
    "\n",
    "    sns.heatmap(df_normalized.T, annot=True, fmt='.3f', cmap='RdYlGn',\n",
    "                ax=axes[1, 0], cbar_kws={'label': 'Normalized Score (Higher = Better)'})\n",
    "    axes[1, 0].set_title('Normalized Metrics Heatmap')\n",
    "\n",
    "    # Overall similarity ranking\n",
    "    # Create composite score (higher is better)\n",
    "    composite_score = (df_normalized['SSIM'] + df_normalized['Correlation'] +\n",
    "                       df_normalized['Cosine_Similarity'] + df_normalized['PSNR'] +\n",
    "                       df_normalized['MSE'] + df_normalized['MAE']) / 6\n",
    "\n",
    "    sorted_indices = composite_score.sort_values(ascending=False)\n",
    "    axes[1, 1].barh(range(len(sorted_indices)), sorted_indices.values, color='orange', alpha=0.7)\n",
    "    axes[1, 1].set_yticks(range(len(sorted_indices)))\n",
    "    axes[1, 1].set_yticklabels(sorted_indices.index)\n",
    "    axes[1, 1].set_title('Overall Similarity Ranking')\n",
    "    axes[1, 1].set_xlabel('Composite Similarity Score')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_results:\n",
    "        fig.savefig('summary_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Print detailed results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED SIMILARITY ANALYSIS RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for img_name, metrics in all_metrics.items():\n",
    "        print(f\"\\n{img_name}:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"SSIM (Structural Similarity):     {metrics['SSIM']:.4f}\")\n",
    "        print(f\"PSNR (Peak SNR):                  {metrics['PSNR']:.2f} dB\")\n",
    "        print(f\"MSE (Mean Squared Error):         {metrics['MSE']:.6f}\")\n",
    "        print(f\"RMSE (Root Mean Squared Error):   {metrics['RMSE']:.6f}\")\n",
    "        print(f\"MAE (Mean Absolute Error):        {metrics['MAE']:.6f}\")\n",
    "        print(f\"Correlation:                      {metrics['Correlation']:.4f}\")\n",
    "        print(f\"Cosine Similarity:                {metrics['Cosine_Similarity']:.4f}\")\n",
    "        if 'Histogram_Intersection' in metrics:\n",
    "            print(f\"Histogram Intersection:           {metrics['Histogram_Intersection']:.4f}\")\n",
    "        print(f\"Edge SSIM:                        {metrics['Edge_SSIM']:.4f}\")\n",
    "\n",
    "    print(f\"\\nRANKING (Best to Worst Similarity):\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, (img_name, score) in enumerate(sorted_indices.items(), 1):\n",
    "        print(f\"{i}. {img_name}: {score:.4f}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45f37442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (256, 256, 3)\n",
      "\n",
      "Processing comparison image 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "the input array must have size 3 along `channel_axis`, got (3, 256, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m KFBio_to_3 = image_to_label(src_img, \u001b[32m3\u001b[39m, L_hyperparam)\n\u001b[32m     12\u001b[39m KFBio_to_4 = image_to_label(src_img, \u001b[32m4\u001b[39m, L_hyperparam)  \n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m results = \u001b[43manalyze_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_img\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mKFBio_to_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKFBio_to_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKFBio_to_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKFBio_to_4\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 136\u001b[39m, in \u001b[36manalyze_images\u001b[39m\u001b[34m(original, comparison_paths, save_results)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessing comparison image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Load comparison image\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m comparison, comparison_gray = \u001b[43mload_and_preprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Check if images have the same dimensions\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original.shape != comparison.shape:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mload_and_preprocess_image\u001b[39m\u001b[34m(img_array)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Convert to grayscale if needed for some metrics\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(img.shape) == \u001b[32m3\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     img_gray = \u001b[43mcolor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrgb2gray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     21\u001b[39m     img_gray = img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/py312/lib/python3.12/site-packages/skimage/_shared/utils.py:445\u001b[39m, in \u001b[36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    442\u001b[39m channel_axis = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mchannel_axis\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.isscalar(channel_axis):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/py312/lib/python3.12/site-packages/skimage/color/colorconv.py:982\u001b[39m, in \u001b[36mrgb2gray\u001b[39m\u001b[34m(rgb, channel_axis)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;129m@channel_as_last_axis\u001b[39m(multichannel_output=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrgb2gray\u001b[39m(rgb, *, channel_axis=-\u001b[32m1\u001b[39m):\n\u001b[32m    943\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute luminance of an RGB image.\u001b[39;00m\n\u001b[32m    944\u001b[39m \n\u001b[32m    945\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    980\u001b[39m \u001b[33;03m    >>> img_gray = rgb2gray(img)\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     rgb = \u001b[43m_prepare_colorarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    983\u001b[39m     coeffs = np.array([\u001b[32m0.2125\u001b[39m, \u001b[32m0.7154\u001b[39m, \u001b[32m0.0721\u001b[39m], dtype=rgb.dtype)\n\u001b[32m    984\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rgb @ coeffs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/py312/lib/python3.12/site-packages/skimage/color/colorconv.py:170\u001b[39m, in \u001b[36m_prepare_colorarray\u001b[39m\u001b[34m(arr, force_copy, channel_axis)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arr.shape[channel_axis] != \u001b[32m3\u001b[39m:\n\u001b[32m    166\u001b[39m     msg = (\n\u001b[32m    167\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mthe input array must have size 3 along `channel_axis`, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    168\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    169\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    172\u001b[39m float_dtype = _supported_float_type(arr.dtype)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m float_dtype == np.float32:\n",
      "\u001b[31mValueError\u001b[39m: the input array must have size 3 along `channel_axis`, got (3, 256, 256)"
     ]
    }
   ],
   "source": [
    "# Definining variables \n",
    "dataset_path_KFbio_1 = f\"/home/leolr-int/data/data/patched/dim_256/Train/Subset3_Train_1_KFBio\"\n",
    "KFBio_1 = deeplake.open_read_only(dataset_path_KFbio_1)\n",
    "\n",
    "L_hyperparam = 0.01 #float(input(\"Enter the L hyperparameter (e.g., 0.1): \"))\n",
    "\n",
    "src_img = KFBio_1[200][\"patch\"].transpose((2, 1, 0))\n",
    "KFBio_to_0 = image_to_label(src_img, 0, L_hyperparam)  \n",
    "KFBio_to_1 = image_to_label(src_img, 1, L_hyperparam)  \n",
    "KFBio_to_2 = image_to_label(src_img, 2, L_hyperparam)  \n",
    "KFBio_to_3 = image_to_label(src_img, 3, L_hyperparam)\n",
    "KFBio_to_4 = image_to_label(src_img, 4, L_hyperparam)  \n",
    "\n",
    "\n",
    "results = analyze_images(src_img.transpose((1,2,0)), [KFBio_to_0, KFBio_to_1, KFBio_to_3, KFBio_to_4], save_results=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
