{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ac9d98",
   "metadata": {},
   "source": [
    "# Comparison metrics\n",
    "\n",
    "Because we cannot trust the human eyes to make comparison between pictures, especially if the eye is French and colorblind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959ed37",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "01d892d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages/deeplake/__init__.py:322: UserWarning: Global variable 'KFBio_1' of type <class 'deeplake._deeplake.ReadOnlyDataset'> may cause issues when using fork-based multiprocessing. Consider avoiding global variables of this type, or pass to subprocess as an agrument or by manual pickling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: piq in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from piq) (0.22.0)\n",
      "Requirement already satisfied: numpy in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torchvision>=0.10.0->piq) (2.2.5)\n",
      "Requirement already satisfied: torch==2.7.0 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torchvision>=0.10.0->piq) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torchvision>=0.10.0->piq) (11.2.1)\n",
      "Requirement already satisfied: filelock in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (80.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from torch==2.7.0->torchvision>=0.10.0->piq) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision>=0.10.0->piq) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/leolr-int/miniforge3/envs/py312/lib/python3.12/site-packages (from jinja2->torch==2.7.0->torchvision>=0.10.0->piq) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, os.path.join(\"..\", \"..\", \"src\"))\n",
    "\n",
    "import torch\n",
    "import pyvips\n",
    "import deeplake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%pip install piq\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from skimage.color import rgb2lab\n",
    "from skimage import io, color, filters\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import wasserstein_distance\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from piq import multi_scale_ssim, gmsd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b61145",
   "metadata": {},
   "source": [
    "Functions to migrate image appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2551c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_freq_mutate_np( amp_src, amp_trg, L=0.1 ):\n",
    "    a_src = np.fft.fftshift( amp_src, axes=(-2, -1) )\n",
    "    a_trg = np.fft.fftshift( amp_trg, axes=(-2, -1) )\n",
    "\n",
    "    _, h, w = a_src.shape\n",
    "    b = (  np.floor(np.amin((h,w))*L)  ).astype(int)\n",
    "    c_h = np.floor(h/2.0).astype(int)\n",
    "    c_w = np.floor(w/2.0).astype(int)\n",
    "    \n",
    "\n",
    "    h1 = c_h-b\n",
    "    h2 = c_h+b+1\n",
    "    w1 = c_w-b\n",
    "    w2 = c_w+b+1\n",
    "\n",
    "    a_src[:,h1:h2,w1:w2] = a_trg[:,h1:h2,w1:w2]\n",
    "    a_src = np.fft.ifftshift( a_src, axes=(-2, -1) )\n",
    "    return a_src\n",
    "\n",
    "def modif_FDA_source_to_target_np( src_img, amp_trg, L=0.1 ):\n",
    "    fft_src_np = np.fft.fft2( src_img, axes=(-2, -1) )\n",
    "    amp_src, pha_src = np.abs(fft_src_np), np.angle(fft_src_np)\n",
    "    amp_src_ = low_freq_mutate_np( amp_src, amp_trg, L=L )\n",
    "    fft_src_ = amp_src_ * np.exp( 1j * pha_src )\n",
    "    src_in_trg = np.fft.ifft2( fft_src_, axes=(-2, -1) )\n",
    "    src_in_trg = np.real(src_in_trg)\n",
    "\n",
    "    return src_in_trg\n",
    "\n",
    "def image_to_label(src_img, label, L_hyperparam=0.1):\n",
    "    # computes the transformation of KBio images to the label-based amplitude\n",
    "    trg_amp = np.load(f\"/home/leolr-int/ASTAR_internship/Fourier_Domain_Adaptation/stored_amplitude/label_based_average/average_label_{label}_akoya.npy\")\n",
    "    return modif_FDA_source_to_target_np( src_img, trg_amp, L=L_hyperparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c417e",
   "metadata": {},
   "source": [
    "Load_and_preprocess_image is used to load image anc create a grayscale version (useful for some metrics).\n",
    "\n",
    "compute_similarity_metrics compute all the metrics needed for comparison.\n",
    "\n",
    "comparison_plots displays several plots to show the difference between the source image and its transformed version (for example one coming the label-based average FDA). \n",
    "\n",
    "list_to_comp_plot reproduce the same plots but for several images\n",
    "\n",
    "metrics_summary prints the metrics for each image and displays summary graphs to evaluate the most similar image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6146fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(img_array):\n",
    "    \"\"\"Load image from numpy array and convert to appropriate format\"\"\"\n",
    "    img = img_array.copy()\n",
    "\n",
    "    # Convert to grayscale if needed for some metrics\n",
    "    if len(img.shape) == 3:\n",
    "        img_gray = color.rgb2gray(img)\n",
    "    else:\n",
    "        img_gray = img\n",
    "\n",
    "    # Normalize to [0, 1] range\n",
    "    if img.max() > 1:\n",
    "        img = img.astype(np.float64) / 255.0\n",
    "        img_gray = img_gray.astype(np.float64) / 255.0\n",
    "\n",
    "    return img, img_gray\n",
    "\n",
    "def compute_similarity_metrics(original, comparison):\n",
    "    original, original_gray = load_and_preprocess_image(original)\n",
    "    comparison, comparison_gray = load_and_preprocess_image(comparison)\n",
    "    \"\"\"Compute various similarity metrics between two images\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "\n",
    "    # 1. Structural Similarity Index (SSIM)\n",
    "    metrics['SSIM'] = ssim(original_gray, comparison_gray, data_range=1.0)\n",
    "   \n",
    "    # 2. Peak Signal-to-Noise Ratio (PSNR)\n",
    "    metrics['PSNR'] = psnr(original, comparison, data_range=1.0)\n",
    "\n",
    "    # 3. Root Mean Squared Error (RMSE) to show color deviations\n",
    "    metrics['MSE'] = mse(original, comparison)\n",
    "    metrics['RMSE'] = np.sqrt(metrics['MSE'])\n",
    "\n",
    "    # 4. Normalized Cross-Correlation (NCC)\n",
    "    original_flat = original_gray.flatten()\n",
    "    comparison_flat = comparison_gray.flatten()\n",
    "    correlation, _ = pearsonr(original_flat, comparison_flat)\n",
    "    metrics['Correlation'] = correlation\n",
    "\n",
    "    # 5. Cosine Similarity\n",
    "    metrics['Cosine_Similarity'] = 1 - cosine(original_flat, comparison_flat)\n",
    "\n",
    "    # 6. Earth Mover's Distance (for color images)\n",
    "    if len(original.shape) == 3:\n",
    "        original_uint8 = (original * 255).astype(np.uint8)\n",
    "        comparison_uint8 = (comparison * 255).astype(np.uint8)\n",
    "\n",
    "        # Flatten images to get pixel values\n",
    "        orig_pixels = original_uint8.reshape(-1, 3)\n",
    "        comp_pixels = comparison_uint8.reshape(-1, 3)\n",
    "        \n",
    "        # Option 1: Compare each color channel separately\n",
    "        wasserstein_r = wasserstein_distance(orig_pixels[:, 0], comp_pixels[:, 0])\n",
    "        wasserstein_g = wasserstein_distance(orig_pixels[:, 1], comp_pixels[:, 1])\n",
    "        wasserstein_b = wasserstein_distance(orig_pixels[:, 2], comp_pixels[:, 2])\n",
    "        \n",
    "        # Average across channels\n",
    "        metrics['EMD'] = (wasserstein_r + wasserstein_g + wasserstein_b) / 3\n",
    "        \n",
    "    \n",
    "    # 7. Edge-based similarity using Sobel filters (applied on gray sclae)\n",
    "    edges_orig = filters.sobel(original_gray)\n",
    "    edges_comp = filters.sobel(comparison_gray)\n",
    "    edge_similarity = ssim(edges_orig, edges_comp, data_range=edges_orig.max() - edges_orig.min())\n",
    "    metrics['Edge_SSIM'] = edge_similarity\n",
    "\n",
    "    # 8. Edge-based similarity using Gradient Magnitude Similarity Deviation (applied on colors)\n",
    "    # computed across all channels and then it is averaged\n",
    "    original = original.astype(np.float32)\n",
    "    comparison = comparison.astype(np.float32)\n",
    "    original = np.clip(original, 0.0, 1.0) #because some pixel are above 255\n",
    "    comparison = np.clip(comparison, 0.0, 1.0)\n",
    "\n",
    "    # Convert to PyTorch tensor with shape [1, 3, H, W] (adds batch size)\n",
    "    original_tensor = torch.from_numpy(original).permute(2, 0, 1).unsqueeze(0)\n",
    "    comparison_tensor = torch.from_numpy(comparison).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    # Compute GMSD per channel\n",
    "    gmsd_values = []\n",
    "    for c in range(3):\n",
    "        gmsd_c = gmsd(original_tensor[:, c:c+1], comparison_tensor[:, c:c+1], data_range=1.0)\n",
    "        gmsd_values.append(gmsd_c.item())\n",
    "\n",
    "    metrics[\"GMSD\"] = np.mean(gmsd_values)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def comparison_plots(original, comparison, original_gray, comparison_gray, title):\n",
    "    \"\"\"Create various difference visualizations\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "    fig.suptitle(f'Difference Analysis: {title}', fontsize=16)\n",
    "\n",
    "    # 1. Original image\n",
    "    axes[0, 0].imshow(original, cmap='gray' if len(original.shape) == 2 else None)\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "\n",
    "    # 2. Comparison image\n",
    "    axes[0, 1].imshow(comparison, cmap='gray' if len(comparison.shape) == 2 else None)\n",
    "    axes[0, 1].set_title('Comparison Image')\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    # 3. Difference histogram\n",
    "    diff_flat = (original_gray - comparison_gray).flatten()\n",
    "    axes[0, 2].hist(diff_flat, bins=50, alpha=0.7, color='blue')\n",
    "    axes[0, 2].set_title('Difference Histogram')\n",
    "    axes[0, 2].set_xlabel('Pixel Difference')\n",
    "    axes[0, 2].set_ylabel('Frequency')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "    # 4. Euclidian distance\n",
    "    \n",
    "    #sq_diff = np.linalg.norm(original - comparison, axis=-1) #first way to do it\n",
    "\n",
    "    #this way is closer from human perception:\n",
    "    original_lab = rgb2lab(original)\n",
    "    comparison_lab = rgb2lab(comparison)\n",
    "    sq_diff = np.linalg.norm(original_lab - comparison_lab, axis=-1)\n",
    "    \n",
    "    im2 = axes[1, 0].imshow(sq_diff, cmap='hot')\n",
    "    axes[1, 0].set_title('Euclidian distance of colors')\n",
    "    axes[1, 0].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[1, 0])\n",
    "\n",
    "    # 5. Gradient magnitude\n",
    "    def compute_gradient_magnitude(image):\n",
    "        \"\"\"\n",
    "        Compute gradient magnitude for each channel of a [H, W, 3] image.\n",
    "        Returns array of shape [3, H, W].\n",
    "        \"\"\"\n",
    "        grad_mag = []\n",
    "        for c in range(3):\n",
    "            gx = filters.sobel(image[:, :, c], axis=1)\n",
    "            gy = filters.sobel(image[:, :, c], axis=0)\n",
    "            mag = np.sqrt(gx**2 + gy**2)\n",
    "            grad_mag.append(mag)\n",
    "        return np.stack(grad_mag)  # Shape: (3, H, W)\n",
    "\n",
    "    # Assume original and comparison are [H, W, 3], in [0, 1]\n",
    "    grad_orig = compute_gradient_magnitude(original)\n",
    "    grad_comp = compute_gradient_magnitude(comparison)\n",
    "\n",
    "    # Compute absolute difference and average over channels\n",
    "    grad_diff_map = np.abs(grad_orig - grad_comp).mean(axis=0)  # Shape: (H, W)\n",
    "\n",
    "    # Plot the gradient difference heatmap\n",
    "    im_grad = axes[1, 1].imshow(grad_diff_map, cmap='inferno')\n",
    "    axes[1, 1].set_title('Gradient Magnitude Difference (RGB avg)')\n",
    "    axes[1, 1].axis('off')\n",
    "    plt.colorbar(im_grad, ax=axes[1, 1])\n",
    "\n",
    "    # SSIM map\n",
    "    ssim_map = ssim(original_gray, comparison_gray, data_range=1.0, full=True)[1]\n",
    "    im3 = axes[1, 2].imshow(ssim_map, cmap='RdYlBu')\n",
    "    axes[1, 2].set_title('SSIM Map')\n",
    "    axes[1, 2].axis('off')\n",
    "    plt.colorbar(im3, ax=axes[1, 2])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def list_to_comp_plot(original, list_img, prints=True, save_results=True):\n",
    "    \"\"\"Main function to analyze image similarities\"\"\"\n",
    "\n",
    "    # Load original image\n",
    "    original, original_gray = load_and_preprocess_image(original)\n",
    "    print(f\"Original image shape: {original.shape}\")\n",
    "\n",
    "    # Store all results\n",
    "    all_metrics = {}\n",
    "\n",
    "    # Compare each image with the original\n",
    "    for i, comp_path in enumerate(list_img):\n",
    "        print(f\"\\nProcessing comparison image {i+1}\")\n",
    "\n",
    "        # Load comparison image\n",
    "        comparison, comparison_gray = load_and_preprocess_image(comp_path)\n",
    "\n",
    "        # Check if images have the same dimensions\n",
    "        if original.shape != comparison.shape:\n",
    "            print(f\"Warning: Shape mismatch. Original: {original.shape}, Comparison: {comparison.shape}\")\n",
    "            # Resize comparison to match original\n",
    "            if len(comparison.shape) == 3:\n",
    "                comparison = cv2.resize(comparison, (original.shape[1], original.shape[0]))\n",
    "            comparison_gray = cv2.resize(comparison_gray, (original.shape[1], original.shape[0]))\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = compute_similarity_metrics(original, comparison)\n",
    "        all_metrics[f'Image_{i+1}'] = metrics\n",
    "\n",
    "        # Create visualizations\n",
    "        if prints:\n",
    "            fig = comparison_plots(original, comparison, original_gray, comparison_gray, f'Image {i+1}')\n",
    "            plt.show()\n",
    "\n",
    "            if save_results:\n",
    "                fig.savefig(f'/home/leolr-int/ASTAR_internship/Fourier_Domain_Adaptation/images/metrics_visualisation/comparison_image_{i+1}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    # Create summary comparison\n",
    "    #create_summary_comparison(all_metrics, save_results)\n",
    "\n",
    "    return all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "45f37442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (256, 256, 3)\n",
      "\n",
      "Processing comparison image 1\n",
      "\n",
      "Processing comparison image 2\n",
      "\n",
      "Processing comparison image 3\n",
      "\n",
      "Processing comparison image 4\n",
      "\n",
      "Processing comparison image 5\n"
     ]
    }
   ],
   "source": [
    "# Definining variables \n",
    "dataset_path_KFbio_1 = f\"/home/leolr-int/data/data/patched/dim_256/Train/Subset3_Train_1_KFBio\"\n",
    "KFBio_1 = deeplake.open_read_only(dataset_path_KFbio_1)\n",
    "\n",
    "L_hyperparam = 0.01 #float(input(\"Enter the L hyperparameter (e.g., 0.1): \"))\n",
    "    \n",
    "src_img = KFBio_1[200][\"patch\"].transpose((2, 1, 0))\n",
    "KFBio_to_0 = image_to_label(src_img, 0, L_hyperparam).transpose((1, 2, 0))\n",
    "KFBio_to_1 = image_to_label(src_img, 1, L_hyperparam).transpose((1, 2, 0))\n",
    "KFBio_to_2 = image_to_label(src_img, 2, L_hyperparam).transpose((1, 2, 0))\n",
    "KFBio_to_3 = image_to_label(src_img, 3, L_hyperparam).transpose((1, 2, 0))\n",
    "KFBio_to_4 = image_to_label(src_img, 4, L_hyperparam).transpose((1, 2, 0))\n",
    "\n",
    "all_metrics = list_to_comp_plot(src_img.transpose((1,2,0)), [KFBio_to_0, KFBio_to_1, KFBio_to_2, KFBio_to_3, KFBio_to_4], prints=False, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4c52f7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SSIM</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>Cosine_Similarity</th>\n",
       "      <th>EMD</th>\n",
       "      <th>Edge_SSIM</th>\n",
       "      <th>GMSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Image_1</th>\n",
       "      <td>0.002843</td>\n",
       "      <td>4.136358</td>\n",
       "      <td>0.385802</td>\n",
       "      <td>0.621129</td>\n",
       "      <td>0.990623</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>146.896444</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.256807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_2</th>\n",
       "      <td>0.002898</td>\n",
       "      <td>4.136010</td>\n",
       "      <td>0.385833</td>\n",
       "      <td>0.621154</td>\n",
       "      <td>0.976260</td>\n",
       "      <td>0.990195</td>\n",
       "      <td>146.916478</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.256806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_3</th>\n",
       "      <td>0.002761</td>\n",
       "      <td>4.134877</td>\n",
       "      <td>0.385933</td>\n",
       "      <td>0.621235</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>0.991626</td>\n",
       "      <td>146.941808</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.256817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_4</th>\n",
       "      <td>0.002751</td>\n",
       "      <td>4.134588</td>\n",
       "      <td>0.385959</td>\n",
       "      <td>0.621256</td>\n",
       "      <td>0.992097</td>\n",
       "      <td>0.991586</td>\n",
       "      <td>146.950775</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.256818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_5</th>\n",
       "      <td>0.002538</td>\n",
       "      <td>4.133243</td>\n",
       "      <td>0.386079</td>\n",
       "      <td>0.621352</td>\n",
       "      <td>0.992026</td>\n",
       "      <td>0.993129</td>\n",
       "      <td>146.967845</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.256839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SSIM      PSNR       MSE      RMSE  Correlation  \\\n",
       "Image_1  0.002843  4.136358  0.385802  0.621129     0.990623   \n",
       "Image_2  0.002898  4.136010  0.385833  0.621154     0.976260   \n",
       "Image_3  0.002761  4.134877  0.385933  0.621235     0.990628   \n",
       "Image_4  0.002751  4.134588  0.385959  0.621256     0.992097   \n",
       "Image_5  0.002538  4.133243  0.386079  0.621352     0.992026   \n",
       "\n",
       "         Cosine_Similarity         EMD  Edge_SSIM      GMSD  \n",
       "Image_1           0.990000  146.896444   0.002028  0.256807  \n",
       "Image_2           0.990195  146.916478   0.002030  0.256806  \n",
       "Image_3           0.991626  146.941808   0.002029  0.256817  \n",
       "Image_4           0.991586  146.950775   0.002028  0.256818  \n",
       "Image_5           0.993129  146.967845   0.002028  0.256839  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metrics_summary(all_metrics, prints = True, save_results=True):\n",
    "    \"\"\"Create summary comparison of all metrics\"\"\"\n",
    "\n",
    "    # Convert to DataFrame for easier plotting\n",
    "    df = pd.DataFrame(all_metrics).T\n",
    "\n",
    "\n",
    "    # Define metrics for comprehensive analysis\n",
    "    metrics_for_analysis = ['SSIM', 'Correlation', 'Cosine_Similarity', 'PSNR', 'RMSE', 'Edge_SSIM', 'GMSD', 'EMD']\n",
    "    df_analysis = df[metrics_for_analysis].copy()\n",
    "\n",
    "    # Normalization function with consistent scaling\n",
    "    def normalize_metric(series, higher_is_better=True):\n",
    "        \"\"\"Normalize metrics to 0-1 scale for fair comparison\"\"\"\n",
    "        min_val = series.min()\n",
    "        max_val = series.max()\n",
    "        range_val = max_val - min_val\n",
    "        \n",
    "        if range_val == 0:\n",
    "            return pd.Series(np.ones(len(series)), index=series.index)\n",
    "        \n",
    "        if higher_is_better:\n",
    "            return (series - min_val) / range_val\n",
    "        else:\n",
    "            return (max_val - series) / range_val\n",
    "\n",
    "    # Create normalized metrics DataFrame\n",
    "    df_normalized = pd.DataFrame(index=df_analysis.index)\n",
    "    \n",
    "    # Define which metrics are better when higher\n",
    "    higher_is_better_metrics = {\n",
    "        \"PSNR\": True,\n",
    "        \"RMSE\": False,\n",
    "        \"SSIM\": True,\n",
    "        \"Edge_SSIM\": True,\n",
    "        \"GMSD\": False,\n",
    "        \"Correlation\": True,\n",
    "        \"Cosine_Similarity\": True,\n",
    "        \"EMD\": False\n",
    "    }\n",
    "    \n",
    "    # Normalize each metric appropriately\n",
    "    for metric in metrics_for_analysis:\n",
    "        df_normalized[metric] = normalize_metric(\n",
    "            df_analysis[metric], \n",
    "            higher_is_better_metrics[metric]\n",
    "        )\n",
    "\n",
    "\n",
    "    # Calculate weighted composite score\n",
    "    # Weights based on metric importance for image similarity assessment\n",
    "    metric_weights = {\n",
    "        \"PSNR\": 0.10,\n",
    "        \"RMSE\": 0.10,\n",
    "        \"SSIM\": 0.25,           # Most important structural metric\n",
    "        \"Edge_SSIM\": 0.15,      # Edge preservation is important\n",
    "        \"GMSD\": 0.10,\n",
    "        \"Correlation\": 0.10,\n",
    "        \"Cosine_Similarity\": 0.10,\n",
    "        \"EMD\": 0.10\n",
    "    }\n",
    "    \n",
    "    # Calculate composite score\n",
    "    composite_scores = pd.Series(0.0, index=df_normalized.index)\n",
    "    for metric, weight in metric_weights.items():\n",
    "        composite_scores += weight * df_normalized[metric]\n",
    "\n",
    "    # Sort by composite score (descending)\n",
    "    sorted_scores = composite_scores.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Create summary plots\n",
    "    if prints:\n",
    "        \n",
    "        fig2, axes = plt.subplots(2, 2, figsize=(12, 11))\n",
    "        fig2.suptitle('Summary Comparison of All Images', fontsize=16, y=0.98)\n",
    "\n",
    "        # SSIM comparison\n",
    "        ssim_values = df['SSIM'].values * 100\n",
    "        axes[0, 0].bar(df.index, ssim_values, color='skyblue', alpha=0.7)\n",
    "        axes[0, 0].set_title('Structural Similarity Index (SSIM) in %')\n",
    "        axes[0, 0].set_ylabel('SSIM Value (%)')\n",
    "        axes[0, 0].set_ylim(0, max(ssim_values) * 1.1)\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        for i, v in enumerate(ssim_values):\n",
    "            axes[0, 0].text(i, v + max(ssim_values) * 0.02, f'{v:.2f}', ha='center', va='bottom')\n",
    "\n",
    "        # EMD comparison\n",
    "        emd = df['EMD'].values\n",
    "        bars = axes[0, 1].bar(df.index, emd, color='lightgreen', alpha=0.7)\n",
    "        axes[0, 1].set_title(\"Earth Mover's Distance (EMD)\")\n",
    "        axes[0, 1].set_ylabel('EMD')\n",
    "        axes[0, 1].set_ylim(min(emd) - 0.1 , max(emd) + 0.1 )\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            axes[0, 1].text(bar.get_x() + bar.get_width() / 2., height, f'{height:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "        # Plot normalized metrics heatmap\n",
    "        sns.heatmap(df_normalized.T, ax=axes[1, 0], annot=True, cmap=\"RdYlGn\", \n",
    "                    cbar=True, fmt=\".3f\", linewidths=0.5, linecolor='white',\n",
    "                    cbar_kws={'label': 'Normalized Performance'})\n",
    "        \n",
    "        axes[1, 0].set_title(\"Normalized Performance Metrics\\n(Green = Better Performance)\")\n",
    "        axes[1, 0].set_xlabel(\"Images\")\n",
    "        axes[1, 0].set_ylabel(\"Metrics\")\n",
    "        \n",
    "        # Create horizontal bar chart for ranking\n",
    "        y_positions = range(len(sorted_scores))\n",
    "        bars = axes[1, 1].barh(y_positions, sorted_scores.values, color='orange', alpha=0.7)\n",
    "        axes[1, 1].set_yticks(y_positions)\n",
    "        axes[1, 1].set_yticklabels(sorted_scores.index)\n",
    "        axes[1, 1].set_title('Overall Similarity Ranking\\n(Weighted Composite Score)')\n",
    "        axes[1, 1].set_xlabel('Composite Score')\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
    "        axes[1, 1].set_xlim(0, 1.0)\n",
    "        \n",
    "        # Add score labels on bars\n",
    "        for i, (bar, score) in enumerate(zip(bars, sorted_scores.values)):\n",
    "            axes[1, 1].text(score + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                        f'{score:.3f}', va='center', ha='left', fontsize=9)\n",
    "            \n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        # Print detailed results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DETAILED SIMILARITY ANALYSIS RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        for img_name in df.index:\n",
    "            metrics = all_metrics[img_name]\n",
    "            print(f\"\\n{img_name}:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            print(f\"Correlation:                      {metrics['Correlation']:.6f}\")\n",
    "            print(f\"Cosine Similarity:                {metrics['Cosine_Similarity']:.6f}\")\n",
    "            print(f\"PSNR (Peak SNR):                  {metrics['PSNR']:.2f} dB\")\n",
    "            print(f\"RMSE (Root Mean Squared Error):   {metrics['RMSE']:.6f}\")\n",
    "            print(f\"SSIM (Structural Similarity):     {metrics['SSIM']:.6f}\")\n",
    "            print(f\"Edge SSIM:                        {metrics['Edge_SSIM']:.6f}\")\n",
    "            print(f\"GMSD (Gradient Magnitude Sim Dev): {metrics['GMSD']:.6f}\")\n",
    "            print(f\"Earth Mover's Distance:           {metrics['EMD']:.6f}\")\n",
    "            print(f\"Composite Score:                  {composite_scores[img_name]:.4f}\")\n",
    "\n",
    "        print(f\"\\nRANKING (Best to Worst Similarity):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, (img_name, score) in enumerate(sorted_scores.items(), 1):\n",
    "            print(f\"{i:2d}. {img_name:<20}: {score:.4f}\")\n",
    "\n",
    "        # Print weight information\n",
    "        print(f\"\\nMETRIC WEIGHTS USED:\")\n",
    "        print(\"-\" * 30)\n",
    "        for metric, weight in metric_weights.items():\n",
    "            print(f\"{metric:<25}: {weight:.2f}\")\n",
    "\n",
    "\n",
    "        if save_results:\n",
    "            fig2.savefig('/home/leolr-int/ASTAR_internship/Fourier_Domain_Adaptation/images/metrics_visualisation/summary_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    return df\n",
    "metrics_summary(all_metrics, prints=False, save_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8e419abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMD                  0.028298\n",
       "Correlation          0.006784\n",
       "Cosine_Similarity    0.001269\n",
       "Name: std, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most discriminative metrics\n",
    "\n",
    "df = pd.DataFrame(all_metrics).T\n",
    "\n",
    "# Calculate the standard deviations\n",
    "std_values = df.describe().loc['std']\n",
    "\n",
    "# Sort the standard deviations in descending order and pick the top three\n",
    "top_three_std = std_values.sort_values(ascending=False).head(3)\n",
    "\n",
    "top_three_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b375fb",
   "metadata": {},
   "source": [
    "## Tests to check if Label-based Global FDA works\n",
    "\n",
    "Be careful: there might be a difference between closest amplitude and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definining variables \n",
    "dataset_path_KFbio_1 = f\"/home/leolr-int/data/data/patched/dim_256/Train/Subset3_Train_1_KFBio\"\n",
    "KFBio_1 = deeplake.open_read_only(dataset_path_KFbio_1)\n",
    "\n",
    "L_hyperparam = 0.01 #float(input(\"Enter the L hyperparameter (e.g., 0.1): \"))\n",
    "    \n",
    "src_img = KFBio_1[200][\"patch\"].transpose((2, 1, 0))\n",
    "KFBio_to_0 = image_to_label(src_img, 0, L_hyperparam).transpose((1, 2, 0))\n",
    "KFBio_to_1 = image_to_label(src_img, 1, L_hyperparam).transpose((1, 2, 0))\n",
    "KFBio_to_2 = image_to_label(src_img, 2, L_hyperparam).transpose((1, 2, 0))\n",
    "KFBio_to_3 = image_to_label(src_img, 3, L_hyperparam).transpose((1, 2, 0))\n",
    "KFBio_to_4 = image_to_label(src_img, 4, L_hyperparam).transpose((1, 2, 0))\n",
    "\n",
    "all_metrics = list_to_comp_plot(src_img.transpose((1,2,0)), [KFBio_to_0, KFBio_to_1, KFBio_to_2, KFBio_to_3, KFBio_to_4], prints=False, save_results=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
